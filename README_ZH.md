# Twinkle: Training workbench to make your model glow

<p align="center">
    <img src="assets/slogan.png" width="200"/>
<p>
<p align="center">
<a href="https://modelscope.cn/home">ModelScope</a>
<br>
        <a href="README.md">English</a>&nbsp ï½œ &nbspä¸­æ–‡&nbsp
</p>

<p align="center">
<img src="https://img.shields.io/badge/python-3.11-5be.svg">
<img src="https://img.shields.io/badge/pytorch-%E2%89%A52.0-orange.svg">
<a href="https://pypi.org/project/twinkle/"><img src="https://badge.fury.io/py/twinkle.svg"></a>
<a href="https://github.com/modelscope/twinkle/blob/main/LICENSE"><img src="https://img.shields.io/github/license/modelscope/twinkle"></a>
<a href="https://pepy.tech/project/twinkle-kit"><img src="https://pepy.tech/badge/twinkle-kit"></a>
<a href="https://github.com/modelscope/twinkle/pulls"><img src="https://img.shields.io/badge/PR-welcome-55EB99.svg"></a>
</p>

<p align="center">
        <a href="https://twinkle-kit.readthedocs.io/en/latest/">è‹±æ–‡æ–‡æ¡£</a> &nbsp ï½œ &nbsp <a href="https://twinkle-kit.readthedocs.io/zh-cn/latest/">ä¸­æ–‡æ–‡æ¡£</a> &nbsp
</p>

## âœ¨ Twinkle æ˜¯ä»€ä¹ˆï¼Ÿ

Twinkleâœ¨ æ˜¯ä¸€ä¸ªè½»é‡çº§çš„å®¢æˆ·ç«¯-æœåŠ¡ç«¯è®­ç»ƒæ¡†æ¶ï¼Œé‡‡ç”¨æ¨¡å—åŒ–ã€é«˜å†…èšçš„æ¥å£è®¾è®¡ã€‚æ— è®ºä½ æ˜¯ä½¿ç”¨ `torchrun` åœ¨æœ¬åœ°æ‰§è¡Œï¼Œè¿˜æ˜¯è·¨ Ray é›†ç¾¤æ‰©å±•è®­ç»ƒï¼ŒTwinkleâœ¨ é€šè¿‡å°†è®­ç»ƒé€»è¾‘å°è£…æˆæ ‡å‡†åŒ– API æ¥æ¶ˆé™¤åŸºç¡€è®¾æ–½å±‚é¢çš„æ‘©æ“¦ã€‚é™¤äº†ç®€å•çš„æŠ½è±¡ä¹‹å¤–ï¼ŒTwinkleâœ¨ è¿˜ä½œä¸ºå¼ºå¤§çš„åç«¯å’Œç½‘å…³ï¼Œå®ç°æ— æœåŠ¡å™¨è®­ç»ƒå³æœåŠ¡ï¼ˆTaaSï¼‰ã€‚å®ƒæä¾›çš„æ¥å£æ˜¯ [Tinker](https://thinkingmachines.ai/tinker/) API çš„_è¶…é›†_ï¼Œå› æ­¤å¯ä»¥é€šè¿‡ Tinker å®¢æˆ·ç«¯æˆ–åŸç”Ÿ Twinkleâœ¨ å®¢æˆ·ç«¯ï¼ˆæä¾›æ›´å¤šåŠŸèƒ½ï¼‰æ¥è®¿é—® Twinkleâœ¨ è®­ç»ƒæœåŠ¡ã€‚

ğŸ§© <b>è§£è€¦æ¶æ„</b>ï¼šæ ‡å‡†åŒ–æ¥å£ï¼Œå‘åå…¼å®¹ Tinker APIã€‚<br>
ğŸš€ <b>å¤šç§è¿è¡Œæ¨¡å¼</b>ï¼štorchrun / Ray / HTTPã€‚<br>
ğŸ”Œ <b>å¤šæ ·åŒ–åç«¯</b>ï¼šTransformers / Megatronã€‚<br>
ğŸ‘¥ <b>å¤šç§Ÿæˆ·è®­ç»ƒæœåŠ¡</b>ï¼šåœ¨å…±äº«ä¸€ä¸ªåŸºç¡€æ¨¡å‹éƒ¨ç½²çš„æƒ…å†µä¸‹è®­ç»ƒå¤šä¸ª LoRAã€‚<br>

æ³¨æ„ï¼šTwinkleâœ¨ ç”± [ms-swift](https://github.com/modelscope/ms-swift) èƒŒåçš„å›¢é˜Ÿæ„å»ºï¼Œæˆ‘ä»¬æœŸæœ›è¿™ä¸¤ä¸ªé¡¹ç›®èƒ½å¤Ÿå…±åŒå‘å±•ã€‚æˆ‘ä»¬é¢„è®¡ Twinkleâœ¨ ä¸­çš„ä¸€äº›åŸºç¡€ç»„ä»¶å°†å¯èƒ½è¢« [ms-swift](https://github.com/modelscope/ms-swift) å¤ç”¨ã€‚

|                    é­”æ­ç¤¾åŒºtwinkleç®—æ³•äº¤æµç¾¤                    |
|:------------------------------------------------------:|
| <img src="assets/wechat.jpg" width="200" height="200"> |

## å®‰è£…

### ä½¿ç”¨åŒ…å®‰è£…ï¼š

```shell
pip install 'twinkle-kit'
```

### ä»æºç å®‰è£…ï¼š

```shell
git clone https://github.com/modelscope/twinkle.git
cd twinkle
pip install -e .
```

## æ•™ç¨‹

| è®­ç»ƒç±»å‹                     | æ¨¡å‹æ¡†æ¶ | Cookbook è·¯å¾„                                     |
| ---------------------------- | -------- | ------------------------------------------------- |
| FSDP å¾®è°ƒ                    | transformers    | [è„šæœ¬](cookbook/transformers/fsdp2.py)             |
| FSDP MoE å¾®è°ƒ                | transformers    | [è„šæœ¬](cookbook/transformers/fsdp2_moe.py)         |
| EP MoE å¾®è°ƒ                  | transformers    | [è„šæœ¬](cookbook/transformers/ep_fsdp_qwen3_moe.py) |
| pp/tp/cp å¾®è°ƒ                | megatron        | [è„šæœ¬](cookbook/megatron/tp.py)                    |
| pp/tp/cp MoE å¾®è°ƒ            | megatron        | [è„šæœ¬](cookbook/megatron/tp_moe.py)                |
| tinker å®¢æˆ·ç«¯å¾®è°ƒ            | megatron        | [è„šæœ¬](cookbook/client/tinker/megatron)            |
| tinker å®¢æˆ·ç«¯å¾®è°ƒ/é‡‡æ ·       | transformers    | [è„šæœ¬](cookbook/client/tinker/transformer)         |
| twinkle å®¢æˆ·ç«¯å¾®è°ƒ           | megatron        | [è„šæœ¬](cookbook/client/twinkle/megatron)           |
| twinkle å®¢æˆ·ç«¯å¾®è°ƒ           | transformer     | [è„šæœ¬](cookbook/client/twinkle/transformer)        |

## æ›´æ–°æ—¥å¿—

- ğŸ‰2026-02-13 Twinkleâœ¨ åˆå§‹ç‰ˆæœ¬å‘å¸ƒï¼ŒåŒ…æ‹¬å¯¹æ–‡æœ¬æ¨¡å‹çš„ SFT/PT/RL æ”¯æŒä»¥åŠåœ¨ [ModelScope](https://modelscope.cn) ä¸Šçš„æ— æœåŠ¡å™¨è®­ç»ƒèƒ½åŠ›ã€‚

## ModelScope çš„è®­ç»ƒæœåŠ¡

æˆ‘ä»¬æ­£åœ¨ ModelScope ä¸Šæ¨å‡ºåŸºäº Twinkleâœ¨ æ„å»ºçš„è®­ç»ƒæœåŠ¡ã€‚ç›®å‰å¤„äº _Beta_ é˜¶æ®µã€‚ä½ å¯ä»¥é€šè¿‡åŠ å…¥ [Twinkle-Explorers](https://modelscope.cn/organization/twinkle-explorers) ç»„ç»‡æ¥æ³¨å†Œå…è´¹è®¿é—®ï¼Œå¹¶é€šè¿‡ API ç«¯ç‚¹ `base_url=https://www.modelscope.cn/twinkle` è¿›è¡Œè®­ç»ƒã€‚æ›´å¤šè¯¦æƒ…è¯·å‚é˜…æˆ‘ä»¬çš„[æ–‡æ¡£](docs/source_zh/ä½¿ç”¨æŒ‡å¼•/è®­ç»ƒæœåŠ¡.md)ã€‚

## æ”¯æŒçš„ç¡¬ä»¶

| ç¡¬ä»¶ç¯å¢ƒ | å¤‡æ³¨                                                            |
| -------- | --------------------------------------------------------------- |
| Nvidia GPU | âœ… æ—©æœŸ GPU å¯¹ BF16/Flash-Attn çš„æ”¯æŒå¯èƒ½ä¸å®Œæ•´ |
| æ˜‡è…¾ NPU   | âœ… éƒ¨åˆ†ç®—å­å¯èƒ½ä¸æ”¯æŒ                              |
| PPU        | âœ…                                                               |
| CPU        | æ”¯æŒéƒ¨åˆ†ç»„ä»¶å¦‚ datasetã€dataloader             |

## æ”¯æŒçš„æ¨¡å‹

éšç€æ–°æ¨¡å‹çš„å‘å¸ƒï¼Œæˆ‘ä»¬å°†æ·»åŠ å¯¹æ›´å¤šæ¨¡å‹çš„æ”¯æŒã€‚ä¸‹è¡¨åˆ—å‡ºäº† Twinkleâœ¨ æ¡†æ¶å½“å‰æ”¯æŒçš„æ¨¡å‹ã€‚

>[!æ³¨æ„]
> å¯¹äºé€šè¿‡ `base_url=https://www.modelscope.cn/twinkle` è®¿é—®çš„æ— æœåŠ¡å™¨è®­ç»ƒæœåŠ¡ï¼Œç›®å‰ä¸€æ¬¡åªæ”¯æŒä¸€ä¸ªè®­ç»ƒåŸºåº§ï¼Œå½“å‰æ˜¯ [Qwen3-30B-A3B-Instruct-2507](https://modelscope.cn/models/Qwen/Qwen3-30B-A3B-Instruct-2507)ã€‚


| æ¨¡å‹ç±»å‹          | [ModelScope](https://modelscope.cn) ä¸Šçš„æ¨¡å‹ ID                                                                          | è¦æ±‚             | Megatron æ”¯æŒ | HF æ¨¡å‹ ID                                                                                                |
| ----------------- |--------------------------------------------------------------------------------------------------------------------------| -------------------- | -------------- | ---------------------------------------------------------------------------------------------------------- |
| qwen3 ç³»åˆ—        | [Qwen/Qwen3-0.6B-Base](https://modelscope.cn/models/Qwen/Qwen3-0.6B-Base)~32B                                            | transformers>=4.51   | âœ…               | [Qwen/Qwen3-0.6B-Base](https://huggingface.co/Qwen/Qwen3-0.6B-Base)                                           |
| qwen3_moe ç³»åˆ—    | [Qwen/Qwen3-30B-A3B-Base](https://modelscope.cn/models/Qwen/Qwen3-30B-A3B-Base)                                          | transformers>=4.51   | âœ…               | [Qwen/Qwen3-30B-A3B-Base](https://huggingface.co/Qwen/Qwen3-30B-A3B-Base)                                     |
|                   | [Qwen/Qwen3-30B-A3B](https://modelscope.cn/models/Qwen/Qwen3-30B-A3B)~235B                                               | transformers>=4.51   | âœ…               | [Qwen/Qwen3-30B-A3B](https://huggingface.co/Qwen/Qwen3-30B-A3B)                                               |
| qwen2 ç³»åˆ—        | [Qwen/Qwen2-0.5B-Instruct](https://modelscope.cn/models/Qwen/Qwen2-0.5B-Instruct) ~72B                                   | transformers>=4.37   | âœ…               | [Qwen/Qwen2-0.5B-Instruct](https://huggingface.co/Qwen/Qwen2-0.5B-Instruct)                                   |
|                   | [Qwen/Qwen2.5-0.5B-Instruct](https://modelscope.cn/models/Qwen/Qwen2.5-0.5B-Instruct)~72B                                | transformers>=4.37   | âœ…               | [Qwen/Qwen2.5-0.5B-Instruct](https://huggingface.co/Qwen/Qwen2.5-0.5B-Instruct)                               |
|                   | [Qwen/Qwen2.5-0.5B](https://modelscope.cn/models/Qwen/Qwen2.5-0.5B)~72B                                                  | transformers>=4.37   | âœ…               | [Qwen/Qwen2.5-0.5B](https://huggingface.co/Qwen/Qwen2.5-0.5B)                                                 |
| qwen2_moe ç³»åˆ—    | [Qwen/Qwen1.5-MoE-A2.7B-Chat](https://modelscope.cn/models/Qwen/Qwen1.5-MoE-A2.7B-Chat)                                  | transformers>=4.40   | âœ…               | [Qwen/Qwen1.5-MoE-A2.7B-Chat](https://huggingface.co/Qwen/Qwen1.5-MoE-A2.7B-Chat)                             |
| chatglm4 ç³»åˆ—     | [ZhipuAI/glm-4-9b-chat](https://modelscope.cn/models/ZhipuAI/glm-4-9b-chat)                                              | transformers>=4.42   | âœ˜               | [zai-org/glm-4-9b-chat](https://huggingface.co/zai-org/glm-4-9b-chat)                                         |
|                   | [ZhipuAI/LongWriter-glm4-9b](https://modelscope.cn/models/ZhipuAI/LongWriter-glm4-9b)                                    | transformers>=4.42   | âœ˜               | [zai-org/LongWriter-glm4-9b](https://huggingface.co/zai-org/LongWriter-glm4-9b)                               |
| glm_edge ç³»åˆ—     | [ZhipuAI/glm-edge-1.5b-chat](https://modelscope.cn/models/ZhipuAI/glm-edge-1.5b-chat)                                    | transformers>=4.46   | âœ˜               | [zai-org/glm-edge-1.5b-chat](https://huggingface.co/zai-org/glm-edge-1.5b-chat)                               |
|                   | [ZhipuAI/glm-edge-4b-chat](https://modelscope.cn/models/ZhipuAI/glm-edge-4b-chat)                                        | transformers>=4.46   | âœ˜               | [zai-org/glm-edge-4b-chat](https://huggingface.co/zai-org/glm-edge-4b-chat)                                   |
| internlm2 ç³»åˆ—    | [Shanghai_AI_Laboratory/internlm2-1_8b](https://modelscope.cn/models/Shanghai_AI_Laboratory/internlm2-1_8b)              | transformers>=4.38   | âœ˜               | [internlm/internlm2-1_8b](https://huggingface.co/internlm/internlm2-1_8b)                                     |
|                   | [Shanghai_AI_Laboratory/internlm2-chat-7b](https://modelscope.cn/models/Shanghai_AI_Laboratory/internlm2-chat-7b)        | transformers>=4.38   | âœ˜               | [internlm/internlm2-chat-7b](https://huggingface.co/internlm/internlm2-chat-7b)                               |
| deepseek_v1       | [deepseek-ai/deepseek-vl-7b-chat](https://modelscope.cn/models/deepseek-ai/deepseek-vl-7b-chat)                          | transformers>=4.39.4 | âœ…               | â€”â€”                                                                                                       |
|                   | [deepseek-ai/DeepSeek-V2-Lite](https://modelscope.cn/models/deepseek-ai/DeepSeek-V2-Lite)                                | transformers>=4.39.3 | âœ…               | [deepseek-ai/DeepSeek-V2-Lite](https://huggingface.co/deepseek-ai/DeepSeek-V2-Lite)                           |
|                   | [deepseek-ai/DeepSeek-V2.5](https://modelscope.cn/models/deepseek-ai/DeepSeek-V2.5)                                      | transformers>=4.39.3 | âœ…               | [deepseek-ai/DeepSeek-V2.5](https://huggingface.co/deepseek-ai/DeepSeek-V2.5)                                 |
|                   | [deepseek-ai/DeepSeek-R1](https://modelscope.cn/models/deepseek-ai/DeepSeek-R1)                                          | transformers>=4.39.3 | âœ…               | [deepseek-ai/DeepSeek-R1](https://huggingface.co/deepseek-ai/DeepSeek-R1)                                     |
| deepSeek-r1-distill | [deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B](https://modelscope.cn/models/deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B) ~32B | transformers>=4.37   | âœ…               | [deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B](https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B) |

æ›´è¯¦ç»†çš„æ¨¡å‹æ”¯æŒåˆ—è¡¨ ğŸ‘‰  [å¿«é€Ÿå¼€å§‹.md](docs/source_zh/ä½¿ç”¨æŒ‡å¼•/å¿«é€Ÿå¼€å§‹.md)

## ç¤ºä¾‹ä»£ç 

### ä½¿ç”¨ Ray è®­ç»ƒ

```python
from peft import LoraConfig
import twinkle
from twinkle import DeviceMesh, DeviceGroup
from twinkle.dataloader import DataLoader
from twinkle.dataset import Dataset, DatasetMeta
from twinkle.model import TransformersModel
from twinkle.preprocessor import SelfCognitionProcessor

device_group = [DeviceGroup(name='default',ranks=8,device_type='cuda')]
device_mesh = DeviceMesh.from_sizes(fsdp_size=4, dp_size=2)
# local for torchrun
twinkle.initialize(mode='ray', groups=device_group, global_device_mesh=device_mesh)


def train():
    # to load model from Hugging Face, use 'hf://...'
    base_model = 'ms://Qwen/Qwen2.5-7B-Instruct'
    # 1000 samples
    dataset = Dataset(dataset_meta=DatasetMeta('ms://swift/self-cognition', data_slice=range(1000)))
    # Set template to prepare encoding
    dataset.set_template('Template', model_id=base_model)
    # Preprocess the dataset to standard format
    dataset.map(SelfCognitionProcessor('twinkle LLM', 'ModelScope Community'))
    # Encode dataset
    dataset.encode()
    # Global batch size = 8, for GPUs, so 1 sample per GPU
    dataloader = DataLoader(dataset=dataset, batch_size=8, min_batch_size=8)
    # Use a TransformersModel
    model = TransformersModel(model_id=base_model, remote_group='default')

    lora_config = LoraConfig(
        r=8,
        lora_alpha=32,
        target_modules='all-linear'
    )

    # Add a lora to model, with name `default`
    # Comment this to use full-parameter training
    model.add_adapter_to_model('default', lora_config, gradient_accumulation_steps=2)
    # Add Optimizer for lora `default`
    model.set_optimizer(optimizer_cls='AdamW', lr=1e-4)
    # Add LRScheduler for lora `default`
    model.set_lr_scheduler(scheduler_cls='CosineWarmupScheduler', num_warmup_steps=5,
                           num_training_steps=len(dataloader))
    for step, batch in enumerate(dataloader):
        # Do forward and backward
        model.forward_backward(inputs=batch)
        # Step
        model.clip_grad_and_step()
        if step % 20 == 0:
            # Print metric
            metric = model.calculate_metric(is_training=True)
            print(f'Current is step {step} of {len(dataloader)}, metric: {metric}')
    model.save(f'last-checkpoint')


if __name__ == '__main__':
    train()
```

### ä½¿ç”¨ç±» Tinker API

```python
import os
from tqdm import tqdm
from tinker import types
from twinkle_client import init_tinker_compat_client
from twinkle.dataloader import DataLoader
from twinkle.dataset import Dataset, DatasetMeta
from twinkle.preprocessor import SelfCognitionProcessor
from twinkle.server.tinker.common import input_feature_to_datum

base_model = 'ms://Qwen/Qwen3-30B-A3B-Instruct-2507'
base_url='http://www.modelscope.cn/twinkle'
api_key=os.environ.get('MODELSCOPE_TOKEN')

# Use twinkle dataset to load the data
dataset = Dataset(dataset_meta=DatasetMeta('ms://swift/self-cognition', data_slice=range(500)))
dataset.set_template('Template', model_id=base_model, max_length=256)
dataset.map(SelfCognitionProcessor('twinkle Model', 'twinkle Team'), load_from_cache_file=False)
dataset.encode(batched=True, load_from_cache_file=False)
dataloader = DataLoader(dataset=dataset, batch_size=8)

# Initialize tinker client
service_client = init_tinker_compat_client(base_url, api_key)
training_client = service_client.create_lora_training_client(base_model=base_model[len('ms://'):], rank=16)

# Training loop: use input_feature_to_datum to transfer the input format
for epoch in range(3):
    for step, batch in tqdm(enumerate(dataloader)):
        input_datum = [input_feature_to_datum(input_feature) for input_feature in batch]

        fwdbwd_future = training_client.forward_backward(input_datum, "cross_entropy")
        optim_future = training_client.optim_step(types.AdamParams(learning_rate=1e-4))

        fwdbwd_result = fwdbwd_future.result()
        optim_result = optim_future.result()

    training_client.save_state(f"twinkle-lora-{epoch}").result()
```

## æ¶æ„è®¾è®¡

<img src="assets/framework.jpg" style="max-width: 500px; width: 100%;" />

**Twinkleâœ¨** é‡‡ç”¨è§£è€¦çš„**å®¢æˆ·ç«¯-æœåŠ¡ç«¯æ¶æ„**è®¾è®¡ï¼Œä»¥å®ç°æœ€å¤§çš„çµæ´»æ€§ã€‚å®¢æˆ·ç«¯æä¾›ä¸¤ç§ä¸åŒçš„é›†æˆè·¯å¾„ï¼š

* **Twinkleâœ¨ åŸç”Ÿï¼š** ç¬¦åˆæœåŠ¡ç«¯æ¥å£çš„ APIï¼Œå®ç°æ— ç¼çš„ç«¯åˆ°ç«¯é›†æˆã€‚
* **Tinker å…¼å®¹ï¼š** å®Œå…¨æ”¯æŒåŸç”Ÿ Tinker APIï¼Œä½¿å¼€å‘è€…èƒ½å¤Ÿä½¿ç”¨ Tinker å®¢æˆ·ç«¯æ¥åˆ©ç”¨ Twinkleâœ¨ çš„åç«¯ã€‚

è¿™ç§åŒè·¯å¾„è®¾è®¡ç¡®ä¿å¯ä»¥ä½¿ç”¨ Tinker API è®¿é—® Twinkleâœ¨ çš„è®­ç»ƒæœåŠ¡ï¼Œåªéœ€ç®€å•ä¿®æ”¹ Tinker çš„ base URLã€‚

## å¤šç§Ÿæˆ·

**Twinkleâœ¨** æ”¯æŒåœ¨å…±äº«åŸºç¡€æ¨¡å‹ä¸ŠåŒæ—¶è¿›è¡Œå¤šç§Ÿæˆ·è®­ç»ƒã€‚åˆ©ç”¨ **LoRA æ±  + ç§Ÿæˆ·åº”ç”¨** æ¶æ„ï¼ŒTwinkle èƒ½å¤Ÿè®©å¤šè¾¾ **N ä¸ªç§Ÿæˆ·** åœ¨å®Œå…¨éš”ç¦»çš„æƒ…å†µä¸‹å¹¶è¡Œè®­ç»ƒã€‚è¿™ç§è®¾è®¡æä¾›äº†å‰æ‰€æœªæœ‰çš„çµæ´»æ€§ï¼šä»æ¨¡å‹çš„è§’åº¦æ¥çœ‹ï¼Œæ¯ä¸ªç§Ÿæˆ·çš„ä¼šè¯æ˜¯ç‹¬ç«‹çš„ï¼Œæ”¯æŒå¼‚æ„é…ç½®ï¼ŒåŒ…æ‹¬ç‹¬ç‰¹çš„**æ•°æ®å¡«å……ç­–ç•¥ã€ä¼˜åŒ–å™¨å’ŒæŸå¤±å‡½æ•°**â€”â€”æ‰€æœ‰è¿™äº›éƒ½åœ¨åŒä¸€ä¸ªåŸºç¡€æ¨¡å‹ä¸Šå¹¶å‘è¿è¡Œã€‚

*æ³¨æ„ï¼šæ­¤åŠŸèƒ½ç›®å‰é’ˆå¯¹ [LoRA](https://github.com/huggingface/peft) è¿›è¡Œäº†ä¼˜åŒ–ã€‚*

<img src="assets/multi_lora.png" style="max-width: 500px; width: 100%;" />

ä¾‹å¦‚ï¼š

- ç§Ÿæˆ· Aï¼šåœ¨æœ¬åœ°åŠ è½½ç§æœ‰æ•°æ®é›†ï¼ŒLoRA rank=8ï¼Œä½¿ç”¨åŸºç¡€æ¨¡å‹è¿›è¡Œ SFT
- ç§Ÿæˆ· Bï¼šä» Hub è¿œç¨‹åŠ è½½å¼€æºæ•°æ®é›†ï¼ŒLoRA rank=32ï¼Œä½¿ç”¨åŸºç¡€æ¨¡å‹è¿›è¡Œ PT
- ç§Ÿæˆ· Cï¼šä½¿ç”¨åŸºç¡€æ¨¡å‹è¿›è¡Œ GRPO æŸå¤±è®¡ç®—ï¼Œä½¿ç”¨ Sampler è¿›è¡Œé‡‡æ ·
- ç§Ÿæˆ· Dï¼šä½¿ç”¨åŸºç¡€æ¨¡å‹è¿›è¡Œ logps æ¨ç†

è¿™äº›è¿‡ç¨‹åœ¨å•ä¸ªåŸºç¡€æ¨¡å‹ä¸Šå¹¶å‘æ‰§è¡Œï¼Œå› ä¸º**æ¨¡å‹å’Œé‡‡æ ·å™¨**ä½œä¸º Twinkleâœ¨ ç”Ÿæ€ç³»ç»Ÿä¸­çš„**ä»»åŠ¡æ— å…³ç»„ä»¶**è¢«é›†æˆã€‚å®Œæˆåï¼Œæ£€æŸ¥ç‚¹ä¼šè‡ªåŠ¨æ¨é€åˆ° **ModelScope** æˆ– **HuggingFace** ä»“åº“ï¼ˆé»˜è®¤ä¸ºç§æœ‰ï¼‰ã€‚åœ¨æœåŠ¡ç«¯ï¼ŒTwinkleâœ¨ æä¾›å¼ºå¤§çš„å¤šç§Ÿæˆ·å¥—ä»¶ï¼Œå…·å¤‡**è‡ªåŠ¨åŒ–é›†ç¾¤ç®¡ç†**å’Œ**åŠ¨æ€æ‰©å±•**åŠŸèƒ½ï¼Œä½¿å…¶æˆä¸ºæ„å»ºå¯å®šåˆ¶ã€ä¼ä¸šçº§è®­ç»ƒæœåŠ¡çš„åŸºç¡€ã€‚

> ä½œä¸ºæ¨¡å—åŒ–æ¡†æ¶ï¼ŒTwinkleâœ¨ ä¹Ÿæ”¯æŒè¿œç¨‹ä¸´æ—¶ç‹¬å è®­ç»ƒï¼Œå³å…¨å‚æ•°æ¨¡å¼è®­ç»ƒã€‚

## ğŸ› ï¸ Twinkleâœ¨ æ¨¡å—åŒ–ç”Ÿæ€ç³»ç»Ÿ

<div align="center">
  <table style="width: 100%; border-collapse: separate; border-spacing: 8px;">
    <tr>
      <td width="20%" bgcolor="#f6f8fa" style="border: 1px solid #d0d7de; border-radius: 8px; padding: 12px;">
        <p align="center"><b>Dataset</b><br><sub>æ•°æ®åŠ è½½å’Œé¢„å¤„ç†</sub></p>
      </td>
      <td width="20%" style="border: 1px solid #d0d7de; border-radius: 8px; padding: 12px;">
        <p align="center"><b>Template</b><br><sub>ç¼–ç å’Œè§£ç </sub></p>
      </td>
      <td width="20%" bgcolor="#f6f8fa" style="border: 1px solid #d0d7de; border-radius: 8px; padding: 12px;">
        <p align="center"><b>DataLoader</b><br><sub>æ•°æ®åˆ†å‘å’Œæ‰¹å¤„ç†</sub></p>
      </td>
      <td width="20%" style="border: 1px solid #d0d7de; border-radius: 8px; padding: 12px;">
        <p align="center"><b>Preprocessor</b><br><sub>æ•°æ® ETL</sub></p>
      </td>
      <td width="20%" bgcolor="#f6f8fa" style="border: 1px solid #d0d7de; border-radius: 8px; padding: 12px;">
        <p align="center"><b>InputProcessor</b><br><sub>ä»»åŠ¡ç‰¹å®šçš„è¾“å…¥å¤„ç†</sub></p>
      </td>
    </tr>
    <tr>
      <td bgcolor="#f6f8fa" style="border: 1px solid #d0d7de; border-radius: 8px; padding: 12px;">
        <p align="center"><b>Model</b><br><sub>å¤§æ¨¡å‹ï¼Œæ”¯æŒå¤šç§æ¡†æ¶</sub></p>
      </td>
      <td style="border: 1px solid #d0d7de; border-radius: 8px; padding: 12px;">
        <p align="center"><b>Sampler</b><br><sub>é‡‡æ ·é€»è¾‘</sub></p>
      </td>
      <td bgcolor="#f6f8fa" style="border: 1px solid #d0d7de; border-radius: 8px; padding: 12px;">
        <p align="center"><b>Loss</b><br><sub>æŸå¤±å‡½æ•°</sub></p>
      </td>
      <td style="border: 1px solid #d0d7de; border-radius: 8px; padding: 12px;">
        <p align="center"><b>Metric</b><br><sub>è®­ç»ƒæŒ‡æ ‡æ”¶é›†</sub></p>
      </td>
      <td bgcolor="#f6f8fa" style="border: 1px solid #d0d7de; border-radius: 8px; padding: 12px;">
        <p align="center"><b>Reward</b><br><sub>å¥–åŠ±å‡½æ•°</sub></p>
      </td>
    </tr>
    <tr>
      <td bgcolor="#f6f8fa" style="border: 1px solid #d0d7de; border-radius: 8px; padding: 12px;">
        <p align="center"><b>Advantage</b><br><sub>ä¼˜åŠ¿å‡½æ•°</sub></p>
      </td>
      <td style="border: 1px solid #d0d7de; border-radius: 8px; padding: 12px;">
        <p align="center"><b>CheckpointEngine</b><br><sub>æƒé‡åŒæ­¥</sub></p>
      </td>
      <td bgcolor="#f6f8fa" style="border: 1px solid #d0d7de; border-radius: 8px; padding: 12px;">
        <p align="center"><b>Patch</b><br><sub>æ¨¡å‹ä¿®å¤è¡¥ä¸</sub></p>
      </td>
      <td style="border: 1px solid #d0d7de; border-radius: 8px; padding: 12px;">
        <p align="center"><b>Module</b><br><sub>ç»„ä»¶ï¼Œå¦‚ä¼˜åŒ–å™¨</sub></p>
      </td>
      <td bgcolor="#f6f8fa" style="border: 1px solid #d0d7de; border-radius: 8px; padding: 12px;">
        <p align="center"><b>Kernel</b><br><sub>ç®—å­</sub></p>
      </td>
    </tr>
    <tr>
      <td bgcolor="#f6f8fa" style="border: 1px solid #d0d7de; border-radius: 8px; padding: 12px;">
        <p align="center"><b>Server</b><br><sub>å¯åŠ¨åç«¯é›†ç¾¤</sub></p>
      </td>
      <td style="border: 1px solid #d0d7de; border-radius: 8px; padding: 12px;">
        <p align="center"><b>Client</b><br><sub>å®¢æˆ·ç«¯ä»£ç </sub></p>
      </td>
      <td bgcolor="#f6f8fa" style="border: 1px solid #d0d7de; border-radius: 8px; padding: 12px;">
        <p align="center"><b>Infra</b><br><sub>éš”ç¦» ray å’Œ torchrun çš„å·®å¼‚</sub></p>
      </td>
      <td style="border: 1px solid #d0d7de; border-radius: 8px; padding: 12px;">
        <p align="center"><b>Plugin</b><br><sub>ä½¿ç”¨ hub ç»„ä»¶</sub></p>
      </td>
      <td bgcolor="#f6f8fa" style="border: 1px solid #d0d7de; border-radius: 8px; padding: 12px;">
        <p align="center"><b>Hub</b><br><sub>ä¸ HF/MS åº“å¯¹æ¥</sub></p>
      </td>
    </tr>
  </table>
</div>

## ç¤¾åŒºç»„ä»¶

| ç»„ä»¶ç±»å‹ | ç»„ä»¶é“¾æ¥                                                                                           | ç»„ä»¶åŠŸèƒ½                                                                      | ä½œè€…              |
| -------- | -------------------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------- | ----------------- |
| Patch    | [qwen3_moe_transformers4_patch](https://www.modelscope.cn/models/twinkle-kit/qwen3_moe_transformers4_patch) | ä¿®å¤ Qwen3 MoE æ¨¡å‹åœ¨ FSDP2 è®­ç»ƒæœŸé—´æŒ‚èµ·çš„é—®é¢˜ï¼Œé€‚ç”¨äº transformers==4.x | ModelScope å®˜æ–¹ |

## å¼€æºè´¡çŒ®

Twinkleâœ¨ æ˜¯ç”± ModelScopeï¼ˆé­”æ­ï¼‰ä¸å¼€æºç¤¾åŒºå…±åŒå‘èµ·çš„åä½œé¡¹ç›®ã€‚è¯¥é¡¹ç›®å¾—åˆ°äº†åŒ…æ‹¬**æ‹›å•†é“¶è¡ŒæŠ€æœ¯å›¢é˜Ÿ**åœ¨å†…çš„æŠ€æœ¯ä¼™ä¼´çš„å…³é”®è´¡çŒ®ã€‚

æˆ‘ä»¬è¡·å¿ƒæ„Ÿè°¢å¼€æºç¤¾åŒºï¼Œç‰¹åˆ«æ˜¯ä¸ºæˆ‘ä»¬æä¾›çµæ„Ÿçš„é¡¹ç›®ï¼ŒåŒ…æ‹¬ [Transformers](https://github.com/huggingface/transformers)ã€[MS-SWIFT](https://github.com/modelscope/swift)ã€[veRL](https://github.com/verl-project/verl) åŠ [Tinker](https://github.com/thinking-machines-lab/tinker) ç­‰ã€‚

æˆ‘ä»¬æ¬¢è¿é€šè¿‡ [Issues](https://github.com/modelscope/twinkle/issues) å’Œ [Pull Requests](https://github.com/modelscope/twinkle/pulls) å‚ä¸å¼€æºè´¡çŒ®ã€‚
