# ModelScope上的Twinkle训练服务

在 Twinkle 框架开源的同时，我们依托ModelScope的后台服务，也提供了托管的模型训练服务(Training as a Service），开发者可以通过这一服务，
免费体验Twinkle的训练API。

目前在集群中运行的模型是[Qwen/Qwen3-30B-A3B-Instruct-2507](https://www.modelscope.cn/models/Qwen/Qwen3-30B-A3B-Instruct-2507)。下面介绍具体的使用方法：

## Step 1. 注册ModelScope用户并申请加入 twinkle-explorers 组织

开发者首先需要注册成为ModelScope用户，并申请加入 [Twinkle-Explorers](https://modelscope.cn/organization/twinkle-explorers) 组织，
来获取访问权限。当前免费的Serverless训练体验，还在灰度测试中，暂时只向组织内的用户开放。您也可以通过本地部署服务，来使用Twinkle✨。

注册地址：https://www.modelscope.cn/

在注册并获批加入[Twinkle-Explorers](https://modelscope.cn/organization/twinkle-explorers) 组织后，在此页面获取
访问的API-Key（即ModelScope平台的访问Token）：https://www.modelscope.cn/my/access/token 。

调用端点：`base_url="https://www.modelscope.cn/twinkle"`

## Step 2. 查看 Cookbook 并二次定制开发

我们强烈推荐开发者查看我们的 [cookbook](https://github.com/modelscope/twinkle/tree/main/cookbook/client/tinker)，并根据其中的训练代码进行二次开发。

> 目前的服务兼容tinker client，因此请使用tinker的cookbook进行训练。后续我们会支持单服务器支持twinkle/tinker双client。

开发者可以定制数据集/优势函数/奖励/模板等，其中 Loss 部分由于需要在服务端执行，因此当前暂不支持（安全性原因）。
如果需要支持您的额外 Loss，可以将该 Loss 实现上传到 ModelHub 中，并在答疑群中或者 issue 中联系我们，将对应组件开放白名单即可使用。

## 附录：支持的训练方式

该模型为纯文本模型，因此暂不支持多模态任务。在纯文本任务中，你可以训练：

1. PT/SFT的常规训练方法，包含Agentic训练
2. GRPO/RLOO等自采样RL算法
3. GKD/On-policy等蒸馏方法，由于魔搭官方端仅支持单模型，因此另一个Teacher/Student模型需要开发者自行准备

当前官方环境仅支持LoRA训练，对LoRA的要求：

1. 最大rank=32
2. 不支持modules_to_save
